{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4479b171",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align : center\"> <font color=\"red\" size=8>RANDOM FOREST ALGORITHM</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bc6a60",
   "metadata": {},
   "source": [
    "## <font color=\"dark blue\">WHAT IS RANDOM FOREST ALGORITHM?\n",
    "- It is a type of Bagging algorithm.\n",
    "- A Random Forest is a powerful ensemble learning method that combines multiple decision trees to improve prediction accuracy and reduce overfitting. It's a popular choice for both classification and regression tasks.\n",
    "    \n",
    "    \n",
    "- Random Forest algorithm is a powerful tree learning technique in Machine Learning. It works by creating a number of Decision Trees during the training phase. Each tree is constructed using a random subset of the dataset to measure a random subset of features in each partition. This randomness introduces variability among individual trees, reducing the risk of overfitting and improving overall prediction performance.\n",
    "    \n",
    "    \n",
    "- It is developed by __Leo Breiman and Adele Cutler__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28236132",
   "metadata": {},
   "source": [
    "## <font color=\"dark blue\">HOW RANDOM FOREST ALGORITHM WORKS?\n",
    "- __Ensemble of Decision Trees__: Random Forest leverages the power of ensemble learning by constructing an army of Decision Trees. These trees are like individual experts, each specializing in a particular aspect of the data. Importantly, they operate independently, minimizing the risk of the model being overly influenced by the nuances of a single tree.\n",
    "    \n",
    "    \n",
    "- __Random Feature Selection__: To ensure that each decision tree in the ensemble brings a unique perspective, Random Forest employs random feature selection. During the training of each tree, a random subset of features is chosen. This randomness ensures that each tree focuses on different aspects of the data, fostering a diverse set of predictors within the ensemble.\n",
    "    \n",
    "    - At each node of the tree, a random subset of features is considered for splitting. This helps to reduce correlation between trees and improve diversity\n",
    "    \n",
    "    \n",
    "- __Bootstrap Aggregating or Bagging__: The technique of bagging is a cornerstone of Random Forest's training strategy which involves creating multiple bootstrap samples from the original dataset, allowing instances to be sampled with replacement. This results in different subsets of data for each decision tree, introducing variability in the training process and making the model more robust.\n",
    "    \n",
    "    \n",
    "- __Decision Making and Voting__: When it comes to making predictions, each decision tree in the Random Forest casts its vote. For classification tasks, the final prediction is determined by the mode (most frequent prediction) across all the trees. In regression tasks, the average of the individual tree predictions is taken. This internal voting mechanism ensures a balanced and collective decision-making process."
   ]
  },
  {
   "attachments": {
    "random-forest-algorithm.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "0ecc92d9",
   "metadata": {},
   "source": [
    "![random-forest-algorithm.png](attachment:random-forest-algorithm.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7410af1",
   "metadata": {},
   "source": [
    "## <font color=\"dark blue\">KEY FEATURES OF RANDOM FOREST ALGORITHM\n",
    "- Reduced Overfitting\n",
    "- High Accuracy\n",
    "- Feature Importance\n",
    "- Handles Missing Values\n",
    "- Handles Imbalanced Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19f361af",
   "metadata": {},
   "source": [
    "## <font color=\"dark blue\">WHY USE RANDOM FOREST ALGORITHM?\n",
    "- It takes less training time as compared to other algorithms.\n",
    "- It predicts output with high accuracy, even for the large dataset it runs efficiently.\n",
    "- It can also maintain accuracy when a large proportion of data is missing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac646e4",
   "metadata": {},
   "source": [
    "## <font color=\"blue\">CODE FOR RANDOM FOREST ALGORITHM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e18020b",
   "metadata": {},
   "source": [
    "### <font color=\"orange\">a. CODE FOR RANDOM FOREST CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b82f86bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Of the Model 0.7988826815642458\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.85      0.83       105\n",
      "           1       0.77      0.73      0.75        74\n",
      "\n",
      "    accuracy                           0.80       179\n",
      "   macro avg       0.79      0.79      0.79       179\n",
      "weighted avg       0.80      0.80      0.80       179\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "titanic_data = pd.read_csv(url)\n",
    "\n",
    "# Drop rows with missing target values\n",
    "titanic_data = titanic_data.dropna(subset=['Survived'])\n",
    "\n",
    "# Select relevant features and target variable\n",
    "X = titanic_data[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare']]\n",
    "y = titanic_data['Survived']\n",
    "\n",
    "# Convert categorical variable 'Sex' to numerical using .loc\n",
    "X.loc[:, 'Sex'] = X['Sex'].map({'female': 0, 'male': 1})\n",
    "\n",
    "# Handle missing values in the 'Age' column using .loc\n",
    "X.loc[:, 'Age'].fillna(X['Age'].median(), inplace=True)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest Classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the classifier\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Accuracy Of the Model\",accuracy)\n",
    "print()\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2207b13a",
   "metadata": {},
   "source": [
    "### <font color=\"orange\">b. CODE FOR RANDOM FOREST REGRESSOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "312fe998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error of the Model 0.2553684927247781\n",
      "\n",
      "R2-Score of the Model 0.8051230593157366\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the California Housing dataset\n",
    "california_housing = fetch_california_housing()\n",
    "california_data = pd.DataFrame(california_housing.data, columns=california_housing.feature_names)\n",
    "california_data['MEDV'] = california_housing.target\n",
    "\n",
    "# Select relevant features and target variable\n",
    "X = california_data.drop('MEDV', axis=1)\n",
    "y = california_data['MEDV']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the regressor\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Mean Squared Error of the Model\", mse)\n",
    "print()\n",
    "print(\"R2-Score of the Model\",r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f5ac79",
   "metadata": {},
   "source": [
    "## <font color=\"purple\">PARAMETERS OF RANDOM FOREST CLASS\n",
    "\n",
    "__1. n_estimators__:\n",
    "- The number of decision trees in the forest. More trees generally lead to better performance, but also increase computational cost.\n",
    "\n",
    "__2. criterion__:\n",
    "- The function used to measure the quality of a split. Common options are \"gini\" and \"entropy\".\n",
    "\n",
    "__3. max_depth__:\n",
    "- The maximum depth of each tree. A deeper tree can capture more complex patterns, but it also increases the risk of overfitting.\n",
    "\n",
    "__4. min_samples_split__:\n",
    "- The minimum number of samples required to split an internal node.\n",
    "\n",
    "__5. min_samples_leaf__:\n",
    "- The minimum number of samples required to be at a leaf node.   \n",
    "\n",
    "__6. max_features__:\n",
    "- The number of features to consider when looking for the best split.\n",
    "    - __sqrt__: The square root of the number of features.\n",
    "    - __log2__: The base-2 logarithm of the number of features.\n",
    "\n",
    "__7. bootstrap__:\n",
    "- Whether to use bootstrap sampling to create different subsets of the training data for each tree.\n",
    "\n",
    "__8. oob_score__:\n",
    "- Whether to compute the out-of-bag (OOB) score. The OOB score is the accuracy of the model on samples that were not used to train a particular tree.\n",
    "\n",
    "__9. n_jobs__:\n",
    "- The number of CPU cores to use for parallel processing. A higher value can speed up training.\n",
    "\n",
    "__10. random_state__:\n",
    "- The seed used by the random number generator. This can be useful for reproducibility.\n",
    "\n",
    "__11. class_weight__:\n",
    "- Weights associated with classes in the form {class_label: weight}. This can be useful for imbalanced datasets.\n",
    "\n",
    "__12. ccp_alpha__:\n",
    "- Complexity parameter used for pruning.\n",
    "\n",
    "__13. max_samples__:\n",
    "- The maximum number of samples to draw from the training set for each base estimator.\n",
    "\n",
    "__14. monotonic_cst__:\n",
    "- Constraints on monotonic relationships between features and the target variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d4801b",
   "metadata": {},
   "source": [
    "## <font color=\"dark blue\">DIFFERENCE BETWEEN RANDOM FOREST & BAGGING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23cce72",
   "metadata": {},
   "source": [
    "FEATURES | RANDOM FOREST | BAGGING\n",
    "--------- | ------------- | --------\n",
    "__Base Models___ | Decision Trees Only | Different\n",
    "__Feature Selection__ | Random subset of features | All features is considered\n",
    "__Bias-Variance Trade-off__ | Reduces both bias and variance | Reduces variance\n",
    "__Spliting criteria__ | Node base Spliting | Tree base Spliting"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
